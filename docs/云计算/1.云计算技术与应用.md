[TOC]

## 每次重启后需要检查时间同步，或者等待时间同步，和等待服务启动成功

## openstack

> 全国卷：https://blog.51cto.com/13846778/2507753

> **注意**： 时间同步，需要自己检查同步，不然一些服务可能出错

### 0. 安装过程


```BASH
# 仅主机网卡（100.10）做控制网卡，NAT（200.10）做外网网卡

# controller
hostname
ip
hosts
firewalld
yum
ftp  vsftp
yum install -y iaas-xiandian
/etc/xiandian/openrc.sh  两节点
iaas-pre-host.sh
iaas-install-mysql.sh
iaas-install-keystone.sh
iaas-install-glance.sh
iaas-install-nova-controller.sh 
iaas-install-neutron-controller.sh
iaas-install-neutron-controller-gre.sh 
iaas-install-dashboard.sh 
iaas-install-cinder-controller.sh
iaas-install-swift-controller.sh
iaas-install-trove.sh                 # thca
iaas-install-heat.sh 
iaas-install-ceilometer-controller.sh 


/etc/xiandian/openrc.sh
iaas-pre-host.sh
iaas-install-nova-compute.sh
iaas-install-neutron-compute.sh 
iaas-install-neutron-compute-gre.sh
iaas-install-cinder-compute.sh
iaas-install-swift-compute.sh
iaas-install-ceilometer-compute.sh

```



### 1. IAAS云平台搭建

#### 基础环境

- ```bash
    按以下要求设置主机名、防火墙及SELinux：
    设置控制节点主机名为controller，计算节点主机名为compute；
    # hostnamectl set-hostname controller    
    # hostnamectl set-hostname compute
    关闭控制节点和计算节点的防火墙，设置开机不启动；
    # systemctl stop firewalld		
    # systemctl disable firewalld
    设置控制节点和计算节点的SELinux为Permissive模式；
    # getenforce 
    退出SecureCRT，重新通过ssh连接各节点服务器；
    ctrl+D 
    （1）	使用命令查询控制节点和计算节点的主机名、防火墙是否处于关闭状态及SELinux的状态。以文本形式依次将命令行及查询信息提交到答题框。
    # hostname    
    # systemctl status firewalld
    # getenforce    sten
    
    （2）	在控制节点上通过SecureFX上传两个镜像文件CentOS-7-x86_64-DVD-1511.iso, XianDian-IaaS-v2.1.iso到opt下，通过命令行创建两个目录/opt/centos,/opt/iaas,并将以上镜像文件分别挂载到上述两个目录下，在答题框依次提交上述的命令以及执行结果；
    # mkdir /opt/centos /opt/iaas
    # mount -o loop CentOS-7-x86_64-DVD-1511.iso centos/
    mount: /dev/loop0 is write-protected, mounting read-only
    # mount -o loop XianDian-IaaS-v2.0.iso iaas/
    mount: /dev/loop1 is write-protected, mounting read-only
    
  （3）	配置控制节点本地yum源文件local.repo，搭建ftp服务并配置根目录为指向存放yum源的路径；配置计算节点yum源文件ftp.repo，使用控制节点ftp服务作为yum源，其中节点的地址以主机名表示；
  # cat /etc/yum.repos.d/local.repo 
  [centos]
  name=centos
  baseurl=file:///opt/centos
  gpgcheck=0
  enabled=1
  [iaas]
  name=iaas
  baseurl=file:///opt/iaas/iaas-repo
  gpgcheck=0
  enabled=1
  
  # cat /etc/vsftpd/vsftpd.conf | grep "anon"
  anon_root=/opt/
  
  # cat /etc/yum.repos.d/ftp.repo 
  [centos]
  name=centos
  baseurl=ftp://controller/centos
  gpgcheck=0
  enabled=1
  [iaas]
  name=iaas
  baseurl=ftp://controller/iaas/iaas-repo
  gpgcheck=0
  enabled=1
  
  (4) 时间同步
  iaas-pre-host.sh 后
  [root@controller ~]# cat /etc/ntp.conf 
  restrict -4 default kod notrap nomodify
  restrict -6 default kod notrap nomodify
  restrict 0.0.0.0
  restrict ::1
  restrict 192.168.200.0 mask 255.255.255.0 nomodify notrap
  server 127.127.1.0
  fudge 127.127.1.0 stratum 8
  #server 0.centos.pool.ntp.org iburst
  #server 1.centos.pool.ntp.org iburst
  #server 2.centos.pool.ntp.org iburst
  #server 3.centos.pool.ntp.org iburst
  [root@controller ~]# systemctl restart ntpd
  
  [root@compute ~]# cat /etc/ntp.conf
  restrict 127.0.0.1 
  restrict ::1
  restrict 192.168.200.10 mask 255.255.255.0 nomodify notrap
  server 192.168.200.10 iburst
  #server 0.centos.pool.ntp.org iburst
  #server 1.centos.pool.ntp.org iburst
  #server 2.centos.pool.ntp.org iburst
  #server 3.centos.pool.ntp.org iburst
  
  然后可以尝试停止ntpd服务，然后用ntpdate进行时间同步检查， 最后的数越小越精确
  [root@compute ~]# ntpdate controller
   9 Sep 01:04:59 ntpdate[2306]: adjust time server 192.168.200.10 offset 0.000378 sec
  [root@compute ~]# systemctl restart ntpd
  ```

#### 环境变量配置

- ```BASH
  # sed  -i  -e   "s/PASS=/PASS=000000/"  -e "s/^#//"  /etc/xiandian/openrc.sh
  
  HOST_IP=192.168.100.10
  HOST_NAME=controller
  HOST_IP_NODE=192.168.100.20
  HOST_NAME_NODE=compute
  RABBIT_USER=openstack
  RABBIT_PASS=000000
  DB_PASS=000000
  DOMAIN_NAME=demo
  ADMIN_PASS=000000
  DEMO_PASS=000000
  KEYSTONE_DBPASS=000000
  GLANCE_DBPASS=000000
  GLANCE_PASS=000000
  NOVA_DBPASS=000000
  NOVA_PASS=000000
  NEUTRON_DBPASS=000000
  NEUTRON_PASS=000000
  METADATA_SECRET=000000
  INTERFACE_NAME=eno33554976    enp4s0f1||enp9s0  #（外网网卡名（NAT））
  CINDER_DBPASS=000000
  CINDER_PASS=000000
  BLOCK_DISK=sda3
  TROVE_DBPASS=000000
  TROVE_PASS=000000
  SWIFT_PASS=000000
  OBJECT_DISK=sda4
  STORAGE_LOCAL_NET_IP=192.168.100.20
  HEAT_DBPASS=000000
  HEAT_PASS=000000
  CEILOMETER_DBPASS=000000
  CEILOMETER_PASS=000000
  AODH_DBPASS=000000
  AODH_PASS=000000
  ```

#### 数据库

- ```bash
    （1）	使用脚本安装数据库服务
  [root@controller ~]# /usr/local/bin/iaas-install-mysql.sh
  
    （2）	以root用户登录数据库
  [root@controller ~]# mysql -uroot -p000000
  
    （3）	查询数据库mysql中所有表的信息
  MariaDB [(none)]> use mysql;
  MariaDB [mysql]> show tables;
  
    （4）	查询表user中的host，user，paassword信息
  MariaDB [mysql]> select  host,user,password  from user;
  
    （5）	使用脚本安装keystone服务。将keystone的数据库导出到当前路径下并命名为keystone.sql，查询文件keystone.sql的前五行。
  [root@controller ~]# mysqldump -uroot -p000000 keystone > keystone.sql
  [root@controller ~]# head -n 5 keystone.sql
  
  ```

#### Keystone

- ```bash
  根据平台安装步骤安装至keystone认证服务，在控制节点使用提供的脚本iaas-install-keystone.sh安装
  keystone组件，admin-openrc.sh 文件在/etc/keystone/下。使用openstack 相关命令，查询用户列表信息
  # iaas-install-keystone.sh
  source 认证
  [root@controller ~]# source /etc/keystone/admin-openrc.sh 
  # openstack user list
  使用openstack 相关命令，查询admin用户信息
  # openstack user show admin
  ```

#### Glance

-  ```bash
  1.使用脚本安装glance服务，使用systemctl命令查询glance组件中所有服务的状态。
  # iaas-install-glance.sh 
  # systemctl status openstack-glance*
  2.使用glance 相关命令查询glance镜像列表，并查询CentOS7.2镜像（镜像可自行上传）的详细信息
  上传镜像
  # glance image-create --name "XianDian-SDN" --disk-format qcow2 --container-format bare --progress < /opt/XianDian-SDN.qcow2
  # glance image-list
  # glance image-show 57d51744-e5c0-45bf-90a1-5d3f02f34bac
  ```

#### Nova

- ```bash
  1.使用脚本安装nova服务。使用nova相关命令查询计算节点虚拟机监控器状态。
  [root@controller ~]# iaas-install-nova-controller.sh
  [root@compute ~]# iaas-install-nova-compute.sh
  [root@controller ~]# nova hypervisor-stats
  ```

#### Neutron

- ```bash
  1.使用脚本安装neutron服务，并配置为GRE网络
  [root@controller ~]# iaas-install-neutron-controller.sh
  [root@compute ~]# iaas-install-neutron-compute.sh
  [root@controller ~]# iaas-install-neutron-controller-gre.sh
  [root@compute ~]# iaas-install-neutron-compute-gre.sh
  
  2.创建云主机外部网络为ext-net,类型gre，外部的 共享的，子网为ext-subnet，虚拟机浮动IP网段为192.168.200.100 ~ 192.168.200.200，网关为192.168.200.1;
  # neutron net-create ext-net  --router:external
  # neutron subnet-create  ext-net  --name ext-subnet  --allocation-pool start=192.168.200.10,end=192.168.200.200 --disable-dhcp --gateway 192.168.200.1  192.168.200.0/24
  
  3.创建云主机隧道网络int-net1，类型gre，子网为int-subnet1，虚拟机子网IP网段为10.0.0.100 ~ 10.0.0.200，网关为10.0.0.1；
  # neutron net-create  int-net1
  # neutron subnet-create  int-net1  --name int-subnet1  --allocation-pool start=10.0.0.100,end=10.0.0.200  --enable-dhcp --gateway 10.0.0.1  10.0.0.0/24
  
  4.创建云主机隧道网络int-net2，子网为int-subnet2，虚拟机子网IP网段为10.0.1.100 ~ 10.0.1.200，网关为10.0.1.1;
  # neutron net-create int-net2
  # neutron  subnet-create   int-net2  --name int-subnet2   --allocation-pool start=10.0.1.100,end=10.0.1.200 --enable-dhcp  --gateway 10.0.1.1  10.0.1.0/24
  
  5.添加名为ext-router的路由器，配置路由接口地址，完成隧道网络int-net1和外部网络ext-net的连通。
  # neutron router-create  ext-router
  # neutron  router-gateway-set ext-router  ext-net
  # neutron  router-interface-add  ext-router  int-subnet1
  
  6.使用neutron相关命令查询所创建路由的详细信息。依次将操作命令和返回结果以文本形式提交到答题框。
  # neutron router-show ext-router
  
  7.使用相关命令查询所创建子网的列表信息，并查看内网子网的详细信息。
  # neutron subnet-list
  # neutron subnet-show  df801f44-9f4a-4481-9424-081326474069
  
  ```

#### Dashboard

- ```bash
 1.使用脚本安装dashboard服务，使用curl命令查询网址http://192.168.100.10/dashboard。
  # iaas-install-dashboard.sh
  # curl 	-L http://192.168.100.10/dashboard/       # -L (Follow redirects遵循重定向)
  ```

####  Cinder

> would like to raise ValueError here, but there are just too many unrecognized (obsolete?)
>
> controller的cinder-volumes状态为DOWN，想在这里提出ValueError，但是项目中有太多无法识别的(过时的?)配置选项

- ```BASH
  parted /dev/sda
  (parted) mkpart /dev/sda4
  File system type?  [ext2]?
  Start? 600G
  End? 1400G
  
  (parted) mkpart /dev/sda5
  File system type?  [ext2]?
  Start? 1401G
  End? 2300G
  
  分区后：
  # lsblk
  NAME            MAJ:MIN RM   SIZE RO TYPE MOUNTPOINT
  sda               8:0    0   3.7T  0 disk 
  ├─sda1            8:1    0     1M  0 part 
  ├─sda2            8:2    0   500M  0 part /boot
  ├─sda3            8:3    0 511.8G  0 part 
  │ ├─centos-root 253:0    0   500G  0 lvm  /
  │ └─centos-swap 253:1    0  11.8G  0 lvm  [SWAP]
  ├─sda4            8:4    0 745.1G  0 part   # 对应环境变量cinder
  └─sda5            8:5    0 837.3G  0 part   # 对应环境变量swift
  
  [root@controller ~]# iaas-install-cinder-controller.sh
  [root@compute ~]# iaas-install-cinder-compute.sh
  [root@controller ~]# iaas-install-swift-controller.sh
  #  iaas-install-swift-compute.sh
  trove、heat、ceilometer*2、alarm
  ```


### 2. IAAS云平台运维

> 1.按以下配置在云平台中创建云主机，完成本任务下的相关试题后关闭云主 机。 
>
> 云主机1： 
>
> （1）名称：IaaS 
>
> （2）镜像文件：Xiandian-IaaS-All.qcow2 
>
> （3）云主机类型：4cpu、8G 内存、100G 硬盘 
>
> （4）网络：网络 1：int-net1，绑定浮动 IP 
>
> 网络 2：int-net2 
>
> 注：该镜像已安装 IaaS 平台所有可能使用的组件，用于完成 IaaS 平台相关 运维操作题，必须按以上配置信息配置接入两个网络才能保证云主机运行正常。 根据题目要求，连接相应的云主机或各节点服务器，进行以下答题。
>
> 云主机2：
>
> （1）名称：SDN
>
> （2）镜像文件：centos_7-x86_64_xiandian.qcow2
>
> （3）云主机类型：m1.small
>
> （4）网络：int-net1，绑定浮动ip
>
> 连接相应的云主机，进行以下答题。

#### 数据库管理

- ```bash
  1.登录IaaS云主机，进入数据库，创建本地用户examuser，密码为000000，然后查询mysql数据库中的user表的host，user，password字段。最后赋予这个用户所有数据库的“查询”“删除”“更新”“创建”的本地权限。
  # MariaDB [(none)]> create user 'examuser'@'localhost' identified by '000000';
  # MariaDB [(none)]> use mysql
  # MariaDB [mysql]> select host,user,password from user;
  # MariaDB [mysql]> grant select,delete,update,create on *.* to examuser@"localhost" identified by "000000";
  
  2.使用数据库的相关命令查询数据库的编码方式
  # mysql> show variables like 'char%';     （character_set_database）
  查看默认引擎  # mysql> show variables like 'storage_engine';
  查看mysql支持的存储引擎 # mysql> show variables like 'have%''；
  
  3.进入数据库keystone，通过user表和local_user表做联合更新，u用来做user表别名，lu用来做local_user表别名，sql语句更新neutron用户的enabled状态为0, 更新语句中user表在local_user前面。
  # MariaDB [keystone]> update user u join local_user lu on u.id=lu.user_id set u.enabled=0 where lu.name='neutron';
  
  4.进入数据库 keystone，通过 user 表和 local_user 表做联合查询，u 用来做 user 表别名，lu用来做 local_user 表别名，两表联合查询 nova 用户的 enabled 状态,查询语句中 user 表在local_user 前面
  # MariaDB [keystone]> select name enabled from user u ,local_user lu where u.id=lu.user_id and lu.name='nova';
  
  5.使用一条命令将keystone的数据库导出为当前路径下的keystone.sql文件，并使用命令查询文件keystone.sql的大小
  # mysqldump -uroot -p000000 keystone > keystone.sql
  # ll keystone.sql
  
  ```

#### Keystone运维

- ```bash
  1.在keystone中创建用户testuser，密码为password，创建好之后，使用命令修改testuser的状态为down，并查看testuser的详细信息，
  # openstack user create --domain demo --password password testuser
  +-----------+----------------------------------+
  | Field     | Value                            |
  +-----------+----------------------------------+
  | domain_id | 90477266390143399b2c38419f3b866b |
  | enabled   | True                             |
  | id        | 7a7701ab736d42e1a8ab739df42b0925 |
  | name      | testuser                         |
  +-----------+----------------------------------+
  # openstack user set --disable testuser
  # openstack user show testuser
  +-----------+----------------------------------+
  | Field     | Value                            |
  +-----------+----------------------------------+
  | domain_id | 90477266390143399b2c38419f3b866b |
  | enabled   | False                            |
  | id        | 7a7701ab736d42e1a8ab739df42b0925 |
  | name      | testuser                         |
  +-----------+----------------------------------+
  
  2.将 testuser 用户分配给 admin 项目，赋予用户 user 的权限
  # openstack role add --user testuser --project admin user
  3.通过openstack相关命令获取token值
  # openstack token issue
  
  4.查询认证服务的查询端点信息
  # openstack endpoint list
  
  5.将keystone 的数据库导出为当前路径下的 keystone.sql 文件，并使用 cat 命令查询文件keystone.sql
  # mysqldump -uroot -p000000 keystone > keystone.sql
  # cat keystone.sql
  
  ```

#### Nova运维

- ```bash
  登录IaaS云主机，使用nova相关命令，查询nova所有的监控列表，并查看ID为1的监控主机的详细信息
  # nova hypervisor-list
  +----+---------------------+-------+---------+
  | ID | Hypervisor hostname | State | Status  |
  +----+---------------------+-------+---------+
  | 1  | compute             | up    | enabled |
  +----+---------------------+-------+---------+
  # nova hypervisor-show 1
  
  2.修改云平台中默认项目的实例配额为15个
  # nova quota-class-update --instance 15 default
  # nova quota-defaults 
  +-----------------------------+-------+
  | Quota                       | Limit |
  +-----------------------------+-------+
  | instances                   | 15    |
  | cores                       | 20    |
  | ram                         | 51200 |
  | floating_ips                | 10    |
  | fixed_ips                   | -1    |
  | metadata_items              | 128   |
  | injected_files              | 5     |
  | injected_file_content_bytes | 10240 |
  | injected_file_path_bytes    | 255   |
  | key_pairs                   | 100   |
  | security_groups             | 10    |
  | security_group_rules        | 20    |
  | server_groups               | 10    |
  | server_group_members        | 10    |
  +-----------------------------+-------+
  
  3.修改云平台中默认每个tenant的实例注入文件大小配额为20480个
  # nova quota-class-update --injected-file 20480 default
  | injected_file_content_bytes | 20480 |
  # nova quota-class-show default
  
  4.通过 nova 的相关命令创建云主机类型 clouds，内存为 1024，硬盘为 20G，虚拟内核数量为 2
  # nova flavor-create  clouds auto 1024 20 2
  
  5.使用nova命令，创建一个云主机vm-test，使用cirros镜像，自行连接网络；
  # nova boot --flavor m1.small --image CentOS_6.5_x86_64_XD.qcow2 --nic net-id=c5221f87-5f27-4fb0-9e31-08269c104676 vm-test
  上面只有三个参数，因为安全组和可用域可以不指定，使用默认的
  # nova boot --flavor name \        	#指定flavor				nova flavor-list
  --image id \						#image   				 nova image-list
  --nic net-id=id \					#net-id    				 nova network-list
  --security-groups id\ 				#security-groups-id  	 nova secgroup-list
  --availability-zone nova:compute \	#可用域  在制定的区域:hosts  nova service-list
  vm-test								#vm名字
  nova list    						#查看虚机
  
  openstack命令创建：
  # openstack server create   三个参数和名字
  
  6.使用 openstack 相关命令，启动一个云主机， 云主机类型使用 m1.small，镜像使用 centos6.5，云主机名称为 xxxtest，并 使用 openstack 命令查看此云主机的详细信息。
  # openstack server create --flavor m1.small --image examimage --nic net-id=c5221f87-5f27-4fb0-9e31-08269c104676 xxxtest
  # openstack server show xxxtest
  
  7.使用nova相关命令查询nova资源使用情况的信息
  # # nova usage-list 
  
  8.绑定浮动ip到实例上
  # nova floating-ip-list 
  # nova add-floating-ip vm-hadoop_slaver1 192.168.100.104
  ```

#### Cinder运维

- ```BASH
  1.使用命令查看当前卷组信息，使用lvcreate命令，创建名称为BlockVloume，大小为2G的lvm逻辑卷，查询该逻辑卷详细信息
  (vgs   lvs)
  # lvcreate -n BlockVloume -L 2G cinder-volumes
  # lvdisplay
  
  2.使用“pvcreate”命令创建物理卷，然后通过“vgextend”命令将该物理卷增加到已有的
  块存储卷组中
  # parted /dev/vda
  # vgcreate /dev/vda1
  # vgextend  cinder-volumes  /dev/vda1
  
  3.创建名为“lvm”的卷类型,然后创建一块带“lvm”标识的云硬盘，名称为 BlockVloume，
  大小为 2G，查询该云硬盘详细信息
  # cinder  type-create lvm --is-public true
  # cinder  create --display-name BlockVloume  --volume-type lvm 2
  # cinder show 6b232c83-ea04-4e8d-9d42-ed79f57d0a4d
  
  4.通过命令行创建云硬盘 volume1，大小为 2G，将其设置为只读，查询该云硬盘详细信息
  # cinder  create --display-name volume1 2
  # cinder readonly-mode-update volume1 True
  # cinder show 48d7edba-ba7c-4dc4-a86d-2bfdaaa84cde
  
  5.使用cinder命令创建一个名叫jiami的云硬盘类型，然后将这个类型设置为encrypted，使用jiami这个类型创建一个云硬盘叫encryptionvolume，大小为1G
  # cinder type-create jiami
  # cinder encryption-type-create jiami LuksEncryptor
  # cinder create --name encryptionvolume --volume-type jiami 1
  
  6.(1)登录 http://192.168.100.10/dashboard，创建云主机名为“vm_extend”，镜像使用
  “centos6.5”， flavor 使用“m1.medium”；
  （2）登录“vm_extend”云主机，从该主机的硬盘“/dev/vda”中分出一个 10G 的分区，
  使用这个分区将云主机“vm_extend”根目录所在逻辑分区扩容 5G；
  （3）在云主机上用 df -h 命令查看挂载信息。
  # fisk /dev/vda      添加一个分区
  # reboot             centos6.5需要重启
  [root@host-10-0-0-113 ~]# lsblk
  NAME                        MAJ:MIN RM  SIZE RO TYPE MOUNTPOINT
  vda                         252:0    0   40G  0 disk 
  ├─vda1                      252:1    0  500M  0 part /boot
  ├─vda2                      252:2    0  7.5G  0 part 
  │ ├─VolGroup-lv_root (dm-0) 253:0    0  6.7G  0 lvm  /
  │ └─VolGroup-lv_swap (dm-1) 253:1    0  816M  0 lvm  [SWAP]
  ├─vda3                      252:3    0  4.8G  0 part 
  └─vda4                      252:4    0  9.6G  0 part 
  [root@host-10-0-0-113 ~]# mkfs.xfs /dev/vda3 
  [root@host-10-0-0-113 ~]# pvcreate /dev/vda3
    Physical volume "/dev/vda3" successfully created
  [root@host-10-0-0-113 ~]# vgextend VolGroup /dev/vda3
    Volume group "VolGroup" successfully extended
  [root@host-10-0-0-113 ~]# vgs
    VG       #PV #LV #SN Attr   VSize  VFree 
    VolGroup   2   2   0 wz--n- 10.8g 4.8g
  [root@host-10-0-0-113 ~]# lvextend -L +5G /dev/mapper/VolGroup-lv_root
    Extending logical volume lv_root to 11.71 GiB
    Logical volume lv_root successfully resized
  # 重新加载硬盘， xfs格式需要 xfs_growfs /dev/mapper/VolGroup-lv_root 
  [root@host-10-0-0-113 ~]# resize2fs /dev/mapper/VolGroup-lv_root 
  resize2fs 1.41.12 (17-May-2010)
  Filesystem at /dev/mapper/VolGroup-lv_root is mounted on /; on-line resizing required
  old desc_blocks = 1, new_desc_blocks = 1
  Performing an on-line resize of /dev/mapper/VolGroup-lv_root to 3332096 (4k) blocks.
  The filesystem on /dev/mapper/VolGroup-lv_root is now 3332096 blocks long.
  [root@host-10-0-0-113 ~]# df -h
  Filesystem                    Size  Used Avail Use% Mounted on
  /dev/mapper/VolGroup-lv_root   6G  827M   5G   7% /
  tmpfs                         1.9G     0  1.9G   0% /dev/shm
  /dev/vda1                     485M   32M  428M   7% /boot
  
  ```

#### Swift

- ```BASH
  1.登录IaaS云主机，创建swifter用户，并创建swift租户，将swifter用户规划到swift租户下，赋予swifter用户使用swift服务的权限，并通过该用户在swift中创建mycontainer容器
  # openstack user create swifter --password 000000 --domain xiandian 
  # openstack project create swift --domain xiandian
  # openstack role add --user swifter --project swift admin
  # swift -A  http://controlller:35357/v3  --os-username swifter --os-user-domain-name xiandian --os-project-name swift --os-project-domain-name xiandian  --os-password 000000 post mycontainer
  
  2.使用 admin 账号在 swift 中创建 mycontainer 容器
  # swift -U admin:admin -K 000000  post mycontainer
  
  3.使用命令查看 swift 服务状态，然后创建一个容器，并使用命令查看容器列表。
  # openstack-status  | grep swift
  # swift post container1
  # swift list
  
  4.使用 swift 相关命令查看一个容器的状态，然后往这个容器中上传一个文件（文件可以自行创建）。
  # swift stat container1
  # swift upload  container1 test.txt
  
  5.使用 swift 相关命令，查询 swift 对象存储服务可以存储的单个文件大小的最大值。
  # swift capabilities
  
  6.登录 iaas 云主机，使用 openstack 命令，创建一个容器，并查询，上传一个文件（可自行创建）到这个容器中，并查询。
  # openstack container create container2
  # openstack container show container2
  # openstack object create container2 test.txt   上传对象（文件）
  # openstack object list container2
  
  ```

#### Glance运维

- ```BASH
  1.使用镜像文件CentOS_6.5_x86_64_XD.qcow2创建glance镜像xiandian6.5，格式为qcow2。
  查看glance配置文件，找到默认的镜像存储目录，进入到存储目录中，使用qemu命令查看刚才上传的镜像的信息,将操作命令和返回结果以文本形式提交到答题框。
  # glance image-create \
  --name "xiandian6.5" \
  --disk-format qcow2 \
  --container bare \
  --progress < /opt/iaas/images/CentOS_6.5_x86_64_XD.qcow2
  # cat /etc/glance/glance-api.conf |grep image|grep -Ev '^#|^$'
  filesystem_store_datadir = /var/lib/glance/images/
  # cd /var/lib/glance/images/
  # qemu-img info 4993a163-c6de-4fcd-9032-c45be06ee913
  
  2.上传完毕后，通过一条组合命令获取镜像列表信息，该组合命令包含：
  （1）使用curl命令获取镜像列表信息；
  （2）使用openstack相关命令获取的token值；
  （3）仅使用awk命令且用空格作为分隔符获取token具体参数值。	
  # curl -i -H "X-Auth-Token:$(openstack token issue | awk -F "|" '/\sid\s/{print $3}')" http://controller:9292/v2/images
  -s（silent）  -H （header） -i (参数打印出服务器回应的 HTTP 标头)
  
  # curl -i -H "X-Auth-Token:$(openstack token issue | awk -F "|" '/\sid\s/{print $3}')" http://controller:9292/v2/images |sed 's/,/\n/g'
  加了sed替换，为换行显示，方便查看
  
  3.通过一条组合命令获取该镜像详细信息，该组合命令要求：
  （1）不能使用任何 ID 作为参数；
  （2）使用 openstack 相关命令获取详细信息；
  （3）使用 glance 相关命令获取镜像对应关系；
  （4）仅使用 awk 命令且用“|”作为分隔符获取 ID 值。
  # openstack image show `glance image-list |awk -F '|' '/xiandian6.5/ {print $2}'`
  
  4.使用curl的方法，查询glance image api 的状态和版本信息。
  
  
  5.使用systemctl 相关命令，在一条命令中查询glance组件中所有服务的状态信息
  # systemctl | grep glance
  
  ```

#### Neutron运维

- ```BASH
  1.使用neutron相关命令查询网络服务的列表信息,并查询网络服务DHCP agent的详细信息
  # neutron agent-list
  # neutron agent-show 75aa4432-93be-494f-abdb-a57fea9933f0
  
  2.使用 neutron 相关命令查询网络服务的列表信息，并已下图的形式打印出来
  # neutron agent-list -c binary -c agent_type -c alive
  
  3.仅使用 neutron 相关命令查询网络服务的列表信息中的“binary”一列
  # neutron agent-list -c binary
  
  4.使用 ovs-vswitchd 管理工具的相关命令查询计算节点的网桥列表信息
  # ovs-vsctl   list-br
  
  5.使用 ovs-vswitchd 管理工具的相关命令查询控制节点的网桥 br-ex 的端口列表信息
  # ovs-vsctl list-ports br-ex
  
  6.neutron命令创建网络和子网
  # neutron net-create --shared --provider:physical_network net172_16_1 --provider:network_type flat cheng
  # neutron subnet-create --name cheng --allocation-pool start=172.16.1.101,end=172.16.1.250 --dns-nameserver 223.5.5.5 --gateway 172.16.1.254 cheng 172.16.1.0/24
  
  # neutron net-list
  # neutron subnet-list
  ```

#### Heat运维

- ```bash
  1.登录iaas云主机，使用heat相关命令，查询heat最新版本模板的功能列表，将操作命令和返回结果以文本形式提交到答题框。
  # heat template-version-list 
  | heat_template_version.2016-04-08     | hot  |
  +--------------------------------------+------+
  # heat template-function-list heat_template_version.2016-04-08
  
  2.从考试系统附件下载 server.yml 文件，通过命令行使用 server.yml 文件创建栈 mystack，指定配置参数为镜像 centos7、网络 int-net2
  # neutron net-list
  # glance image-list
  # heat stack-create -f server.yml  -P ImageID=f93e836c-4905-433f-8f01-97391eb62d7c -P NetID=41cbb614-0071-4818-b8d7-230bc7d6f9af mystack
  ```



#### Rabbitmq运维

- ```bash
  登录“iaas_all”云主机。
  （1）使用rabbitmqctl命令创建用户xiandian-admin，密码为admin；
  # rabbitmqctl add_user xiandian-admin admin
  
  （2）给xiandian-admin用户创建administrator角色并查询；
  设置用户角色：rabbitmqctl set_user_tags {username} {tag ...}
  Tag可以为 administrator,monitoring, management
  # rabbitmqctl set_user_tags xiandian-admin administrator
  
  （3）授予用户xiandian-admin对本机所有资源可写可读可执行的权限，查询xiandian-admin用户的授权信息。 然后查询xiandian-admin 用户的授权信息
  set_permissions [-p <vhost>] <user> <conf> <write> <read>
  # rabbitmqctl set_permissions xiandian-admin '.*' '.*' '.*'
  # rabbitmqctl list_user_permissions xiandian-admin
  
  4.使用rabbitmqctl命令查询集群状态
  # rabbitmqctl cluster_status
  
  ```

#### KVM运维

- ```bash
  1.登录compute节点，使用命令将KVM进程绑定到特定的0-5号cpu上。
  # pgrep -lo kvm
  21701 qemu-kvm
  # taskset -pc 0-5 21701
  
  2.在物理云平台查询云主机IaaS在KVM中的真实实例名，在计算节点使用virsh命令找到该实例名对应的domain-id，使用该domain-id查看云主机IaaS的cpu使用信息
  # nova show test1
  OS-EXT-SRV-ATTR:instance_name        | instance-0000001a
  # virsh domid instance-0000001a
  # virsh vcpuinfo 5
  
  3.在物理云平台查询云主机 IaaS 在 KVM 中的真实实例名，在计算节点使用 virsh 命令找到该实例名对应的 domain-id，使用该 domain-id 关闭云主机 IaaS
  [root@controller ~]# nova list
  [root@controller ~]# nova show  IaaS|grep instance
  [root@compute ~]# virsh domid instance-00000007
  [root@compute ~]# virsh shutdown 8
  
  4.登录 controller 节点，首先查看当前系统有多少大页，然后设置大页数量为 20 并查看，其次使用命令使配置永久生效，最后将大页挂载到/dev/hugepages/上。
  [root@controller ~]# cat /proc/meminfo|grep HugePages
  [root@controller ~]# echo 20 > /proc/sys/vm/nr_hugepages
  [root@controller ~]# cat /proc/meminfo|grep HugePages
  [root@controller ~]# sysctl -w vm.nr_hugepages=20
  [root@controller ~]# mount -t hugetlbfs hugetlbfs /dev/hugepages/
  
  ```

#### 数据加密管理

- ```bash
  前提：按要求配置静态fixed_key，使cinder和nova组件可以使用加密过的Block Storage卷服务，配置好之后，创建一个卷类型叫luks，并把这个类型配置为加密类型，cipher使用“aes-xts-plain64”，key_size使用“512”，control-location使用“front-end”，Provider使用“nova.volume.encryptors.luks.LuksEncryptor”。
  
  （1）登录“iaas_all”云主机，创建两块云硬盘，分别叫“unencrypted volume”和“encrypted volume”大小都是1G，前者不加密，后者使用luks加密卷类型；
  # fdisk /dev/sdd  					#创建磁盘 
  # cryptsetup luksFormat /dev/sdd    #加密磁盘
  WARNING!
  This will overwrite data on /dev/sdd irrevocably.
  Are you sure? (Type uppercase yes): YES     #大写YES
  Enter passphrase:                           #密码长度最少8位，不能太简单
  Verify passphrase: 
  ```

#### Cinder排错

- ```bash
  在云平台后台管理的过程中块存储功能无法使用，错误现象为创建的云硬盘状态为error。找出错误原因，进行修复，修复之后创建云硬盘，查询云硬盘的详细信息。依次将错误的内容、修复的操作以及查询到信息以文本形式提交到答题框。
  ```

#### Glance排错

- ```bash
  在云平台后台管理的过程中无法上传镜像，找出错误原因，并进行修复，修复之后使用cirros-0.3.4-x86_64-disk.img创建名为cirros的镜像，查询镜像的详细信息。依次将错误的内容、修复的操作以及查询到的信息以文本形式提交到答题框。
  
  ```

#### 工程总结报告

- ![image-20200916130928560](.\img\image-20200916130928560.png)

  ```BASH
  1.绘制IaaS平台的架构组件图，组件包含本次项目实施中涉及到的IaaS组件服务，架构组件绘制各组件之间的关系。并对架构图进行解释说明。
  组件包括Horizon、Neutron、Cinder、Nova、Glance、Swift、Cinder、Ceilmeter、Keystone、Heat、Sahara。
  解释说明：控制面板同每个服务都有调用关系，Keystone和每个服务都有认证管理。Neutron为VM提供网络服务、Cinder为VM提供快存储、Swift提供云存储、Glance为VM提供镜像、Nova是VM操作的调度引擎。Ceilometer是监控服务，Heat是模板服务。Sahara是大数据集群部署服务。
  
  ```

  


```bash
# fdisk /dev/sdb       创建硬盘
# pvcreate /dev/sdb1   创建
# pvcreate /dev/sdc1
# vgcreate vgtest /dev/sdb1 /dev/sdc1
# lvcreate -L 1G -n 'encrypted-volume' cinder-volumes
```







## Hadoop

### 1.Hadoop搭建

~~*xml文件*~~

~~*yum源    yum update*~~

>  大数据平台的搭建采用分布式方式部署，部署在云平台的两台虚拟机上，规划大数据平台的部署架构，云主机1部署大数据平台master节点，云主机2部署大数据平台slaver节点。按以下配置在云平台中创建云主机，完成第二部分的相关试题后关闭云主机。
>
> 云主机1：
>
> （1）名称：master
>
> （2）镜像文件：hadoop_master_centos7_x86_xiandian_images-v04.qcow2
>
> （3）云主机类型：4CPU、8G内存、10G硬盘
>
>  (4) 网络：网络1：int-net1，绑定浮动IP
>
> 云主机2：
>
> （1）名称：slaver
>
> （2）镜像文件：hadoop_slaver1_centos7_x86_xiandian_images-v04.qcow2
>
> （3）云主机类型：2CPU、4G内存、10G硬盘
>
>  (4) 网络：网络1：int-net1，绑定浮动IP

#### 基本环境 

- ![](.\img\image-20200722104743389.png)

  ```BASh
  1.更改两台主机的hosts（ip为绑定的网络接口的ip，并非浮动ip）
  # cat  /etc/hosts
  127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4
  ::1         localhost localhost.localdomain localhost6 localhost6.localdomain6
  10.0.0.107 master
  10.0.0.105 slaver1
  2.检查ntp、ambari-server是否启动和slaver1的ntpdate状态
  master  # systemctl status ntpd
  slaver1 # ntpdate master
  master  # systemctl status ambari-server
  3.检查Transparent Huge Pages状态
  # cat /sys/kernel/mm/transparent_hugepage/defrag 
  4.登录网页http：//master：8080修改MapReduce2和Hive配置参数中有黄色三角提示的项
  
  ```

### 2.Hadoop运维

#### 常用命令

- > # Hadoop集群用户的常用命令。
  >
  > # archive
  > 创建一个hadoop档案文件。参考 Hadoop Archives.
  > 用法：hadoop archive -archiveName NAME -p <parent path>  <src>* <dest>
  >
  > # distcp
  > 递归地拷贝文件或目录。参考DistCp指南以获取等多信息。
  > 用法：hadoop distcp <srcurl> <desturl>
  >
  > # fs
  > 用法：hadoop fs [GENERIC_OPTIONS] [COMMAND_OPTIONS]
  > 运行一个常规的文件系统客户端。
  >
  > # fsck
  > 运行HDFS文件系统检查工具。参考Fsck了解更多。
  > 用法：hadoop fsck [GENERIC_OPTIONS] <path> [-move | -delete | -openforwrite] [-files [-blocks [-locations | -racks]]]
  >
  > # jar
  > 运行jar文件。用户可以把他们的Map Reduce代码捆绑到jar文件中，使用这个命令执行。
  > 用法：hadoop jar <jar> [mainClass] args...
  >
  > # job
  > 用于和Map Reduce作业交互和命令。
  > 用法：hadoop job [GENERIC_OPTIONS] [-submit <job-file>] | [-status <job-id>] | [-counter <job-id> <group-name> <counter-name>] | [-kill <job-id>] | [-events <job-id> <from-event-#> <#-of-events>] | [-history [all] <jobOutputDir>] | [-list [all]] | [-kill-task <task-id>] | [-fail-task <task-id>]
  >
  > # pipes
  > 运行pipes作业。
  > 用法：hadoop pipes [-conf <path>] [-jobconf <key=value>, <key=value>, ...] [-input <path>] [-output <path>] [-jar <jar file>] [-inputformat <class>] [-map <class>] [-partitioner <class>] [-reduce <class>] [-writer <class>] [-program <executable>] [-reduces <num>]
  >
  > # version
  > 打印版本信息。
  > 用法：hadoop version
  >
  > # CLASSNAME
  > hadoop脚本可用于调调用任何类。
  > 用法：hadoop CLASSNAME
  > 运行名字为CLASSNAME的类。



> 在Hadoop集群中，只有hdfs用户才有对HDFS文件系统的管理权限，当其它用户对文件系统进行操作，需要给其赋予相应的权限，这里为了方便操作，将所有用户的读写执行权限全部放开，命令如下：
>  su hdfs
> $ hadoop fs -chmod  -R 777 /
> $ hadoop fs -ls /

#### Hdfs

- ```BASH
  1.在HDFS文件系统的根目录下使用一条命令创建递归目录“1daoyun/file”，将附件中的BigDataSkills.txt文件，上传到1daoyun/file目录中，并使用HDFS文件系统检查工具检查文件是否受损，以文本形式提交以上操作命令和输出结果到答题框中。
  [root@master ~]# hadoop fs -mkdir -p /1daoyun/file
  [root@master ~]# hadoop fs -put   /opt/MapReduce/BigDataSkills.txt /1daoyun/file
  [root@master ~]# hadoop fsck /1daoyun/file/BigDataSkills.txt
  
  2.HDFS文件系统的根目录下存在一个/apps的文件目录，要求开启该目录的可创建快照功能，并为该目录文件创建快照，快照名为apps_1daoyun，使用相关命令查看该快照的列表信息。
  [hdfs@master root]$ hdfs dfsadmin -allowSnapshot /apps
  [hdfs@master root]$ hdfs dfs -createSnapshot /apps apps_1daoyun
  [hdfs@master root]$ hadoop fs -ls /apps/.snapshot
  
  3.为了防止操作人员误删文件，HDFS文件系统提供了回收站的功能，但过多的垃圾文件会占用大量的存储空间。要求在先电大数据平台的WEB界面将HDFS文件系统回收站中的文件彻底删除的时间间隔为7天，以文本形式提交修改的文件名称、参数信息和参数值到答题框中。
  # hafs中的fs.trash.interval配置修改为10080
  
  4.Hadoop集群中的主机在某些情况下会出现宕机或者系统损坏的问题，一旦遇到这些问题，HDFS文件系统中的数据文件难免会产生损坏或者丢失，为了保证HDFS文件系统的可靠性，现需要在先电大数据平台的WEB界面将集群的冗余复制因子修改为5，以文本形式提交修改的参数信息和参数值到答题框中。
  # hdfs中的Block replication配置选项修改为5
  
  5.使用命令查看hdfs文件系统中/tmp目录下的目录个数，文件个数和文件总大小，将操作命令和返回结果以文本形式提交到答题框。
  [hdfs@master 2.4.3.0-227]$ hadoop fs -count -h /tmp     -h(人性化地显示大小)
             8            1              1.7 K /tmp
  
  ```

#### MapReduce

- ```BASH
  1.在集群节点中/usr/hdp/2.4.3.0-227/hadoop-mapreduce/目录下，存在一个案例JAR包hadoop-mapreduce-examples.jar。运行JAR包中的PI程序来进行计算圆周率π的近似值，要求运行5次Map任务，每个Map任务的投掷次数为5，运行完成后以文本形式提交以上操作命令和输出结果到答题框中。
  [root@master ~]# hadoop jar /usr/hdp/2.4.3.0-227/hadoop-mapreduce/hadoop-mapreduce-examples-2.7.1.2.4.3.0-227.jar pi 5 5
  
  2.运行JAR包中的wordcount程序来对/1daoyun/file/BigDataSkills.txt文件进行单词计数，将运算结果输出到/1daoyun/output目录中，使用相关命令查询单词计数结果，以文本形式提交以上操作命令和输出结果到答题框中。
  [hdfs@master   hadoop-mapreduce]$ cd /usr/hdp/2.4.3.0-227/hadoop-mapreduce/ 
  
  [hdfs@master   hadoop-mapreduce]$ hadoop jar hadoop-mapreduce-examples.jar wordcount /1daoyun/file/BigDataSkills.txt /1daoyun/output
  
  [hdfs@master root]$ hadoop fs -ls /1daoyun/output
  Found 2 items
  -rw-r--r--   3 hdfs hdfs          0 2019-03-28 12:54 /1daoyun/output/_SUCCESS
  -rw-r--r--   3 hdfs hdfs        147 2019-03-28 12:54 /1daoyun/output/part-r-00000
  
  [hdfs@master root]$ hadoop fs -cat /1daoyun/output/part-r-00000
  
  3.当Hadoop集群启动的时候，会首先进入到安全模式的状态，该模式默认30秒后退出。当系统处于安全模式时，只能对HDFS文件系统进行读取，无法进行写入修改删除等的操作。现假设需要对Hadoop集群进行维护，需要使集群进入安全模式的状态，并检查其状态。
  [root@master hadoop-mapreduce]# su hdfs
  [hdfs@master hadoop-mapreduce]$ /bin/hdfs dfsadmin -safemode enter
  Safe mode is ON
  [hdfs@master hadoop-mapreduce]$ /bin/hdfs dfsadmin -safemode leave
  Safe mode is OFF
  
  4.在集群节点中/usr/hdp/2.4.3.0-227/hadoop-mapreduce/目录下，存在一个案例JAR包hadoop-mapreduce-examples.jar。运行JAR包中的sudoku程序来计算下表中数独运算题的结果。运行完成后以文本形式提交以上操作命令和输出结果到答题框中。
  [hdfs@master hadoop-mapreduce]$ hadoop jar hadoop-mapreduce-examples.jar sudoku <input文件>      # 暂无input文件，无法运行
  
  5.在集群节点中/usr/hdp/2.4.3.0-227/hadoop-mapreduce/目录下，存在一个案例JAR包hadoop-mapreduce-examples.jar。运行JAR包中的grep程序来统计文件系统中BigDataSkills.txt文件中“Hadoop”出现的次数，统计完成后，查询统计结果信息。
  [hdfs@master hadoop-mapreduce]$ hadoop jar hadoop-mapreduce-examples.jar grep /1daoyun/test.txt /1daoyun/grep_output if    # 格式：hadoop jar jar包 grep(包程序) input_file output_path word
  
  ```

#### Hbase

- ```BASH
  1.启动先电大数据平台的Hbase数据库，其中要求使用master节点中的RegionServer。在LinuxShell中启动Hbaseshell，查看HBase的版本信息。（数据库命令语言全部使用小写格式）
  hbase(main):001:0> version
  1.1.2.2.4.3.0-227, rUnknown, Fri Sep  9 23:34:30 UTC 2016
  
  2.在HBase数据库中创建表xiandian_user，列族为info，创建完成后查看xiandian_user表的描述信息。然后开启HBase的安全认证功能，在HBase Shell中设置root用户拥有表xiandian_user的读写与执行的权限，设置完成后，使用相关命令查看其权限信息。将上述所有操作命令（相关数据库命令语言请全部使用小写格式）和返回结果以文本形式提交到答题框。
  [root@master ~]# hbase shell
  hbase(main):001:0> create 'xiandian_user','info'
  hbase(main):003:0> describe 'xiandian_user'
  hbase(main):001:0> grant 'root','RWX','xiandian_user'
  hbase(main):002:0> user_permission 'xiandian_user'
  
  ```

#### Hive

- ```BASH
  1.启动先电大数据平台的Hive数据仓库，启动Hvie 客户端，通过Hive查看hadoop所有文件路径。
  [root@master ~]# hive
  hive> dfs -ls /;
  
  2.使用Hive工具来统计phy_course_xd.txt文件中某高校报名选修各个体育科目的总人数，其中phy_course_xd.txt数据结构如表4-2-1所示，选修科目字段为opt_cour，将统计的结果导入到表phy_opt_count中，通过SELECT语句查询表phy_opt_count内容，将统计语句以及查询命令和输出结果以文本形式提交到答题框。
  							表4-2-1
  stname(string)	stID(int)	class(string)	opt_cour(string)
  # hive> create phy_opt_count (stname string,stID int,class string,opt_cour string) row format delimited fields terminated by '\t';     # 似乎可以不要lines terminated by '\n'
  
  # hive> load data local inpath '/root/phy_course_xd.txt' into table phy_opt_count;
  
  # hive> select * from phy_opt_count;
  
  3.在Hive数据仓库将系统日志weblog_entries.txt中分开的request_date和request_time字段进行合并，并以一个下划线“_”进行分割，如下图所示，其中weblog_entries.txt的数据结构如下所示。
  md5(STRING)	url(STRING)	request_date (STRING)	request_time (STRING)	ip(STRING)
  
  # hive> DROP TABLE IF EXISTS weblog_entries;
  # hive> CREATE EXTERNAL TABLE weblog_entries (
      > md5 STRING,
      > url STRING,
      > request_date STRING,
      > request_time STRING,
      > ip STRING
      > )
      > ROW FORMAT DELIMITED FIELDS TERMINATED BY '\t'
      > LINES TERMINATED BY '\n'
      > LOCATION '/data/hive/weblog/';
  # hive> load data local inpath '/root/tmp/weblog_entries.txt' into table weblog_entries;
  # hive > SELECT concat_ws('_', request_date, request_time) > FROM weblog_entries;
  
  4.使用Hive工具来统计phy_course_xd.txt文件中某高校报名选修各个体育科目的总人数，其中phy_course_xd.txt数据结构如表4-2-1所示，选修科目字段为opt_cour，将统计的结果导入到表phy_opt_count中，通过SELECT语句查询表phy_opt_count内容，将统计语句以及查询命令和输出结果以文本形式提交到答题框。
    表4-2-1 数据结构
    stname(string)	stID(int)	class(string)	opt_cour(string)
  
  
    5.在Hive数据仓库将系统日志weblog_entries.txt中分开的request_date和request_time字段进行合并，并以一个下划线“_”进行分割，如下图所示，其中weblog_entries.txt的数据结构如下表所示。将以上操作命令和输出结果以文本形式提交到答题框。
  md5(STRING)	url(STRING)	request_date (STRING)	request_time (STRING)	ip(STRING)
  # hive> DROP TABLE IF EXISTS weblog_entries;
  # hive> CREATE EXTERNAL TABLE weblog_entries (
        > md5 STRING,
        > url STRING,
        > request_date STRING,
        > request_time STRING,
        > ip STRING
        > )
        > ROW FORMAT DELIMITED FIELDS TERMINATED BY '\t'
        > LINES TERMINATED BY '\n'
        > LOCATION '/data/hive/weblog/';
    # hive> load data local inpath '/root/tmp/weblog_entries.txt' into table weblog_entries;
    # hive > SELECT concat_ws('_', request_date, request_time) > FROM weblog_entries;
  
  ```
